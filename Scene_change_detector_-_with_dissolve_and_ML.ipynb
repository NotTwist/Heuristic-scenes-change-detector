{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Интеллектуальные методы обработки видео"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ноутбук разделен на два задания:\n",
    "   * ### [Эвристический SCD](#first)\n",
    "   * ### [SCD с ML](#second)\n",
    "   \n",
    "Сроки выполнения для каждого задания — одна неделя. Оцениваются задания независимо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1. Scene Change Detector\n",
    "<a id='first'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обязательно к прочтению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Внимание!**\n",
    "\n",
    "Opencv содержит очень много высокоуровневых функций обработки изображений (например, некоторые алгоритмы компенсации движения, отслеживания объектов, распознавания образов). Использование данной библиотеки в данном задании ограничивается:\n",
    "* считыванием входного видео\n",
    "* преобразованием его кадров в другие цветовые пространства\n",
    "* использованием свёрток Собеля\n",
    "\n",
    "Использовать библиотеку numpy можно без ограничений.\n",
    "\n",
    "Если вы хотите использовать функции обработки изображений и видео из другой библиотеки, то оговорите использование этой функции в чате курса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание входных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выборка для тренировки лежит https://titan.gml-team.ru:5003/sharing/yX8enupJV\n",
    "\n",
    "Данные о каждом видео лежат в файле *train_dataset\\info.json*. Это список из словарей, каждый словарь содержит информацию о расположении видео, о расположении ответов на смены сцен и содержит длину видео"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 # Для установки opencv воспользуйтесь командой в терминале conda install -c conda-forge opencv\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "def load_json_from_file(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        return json.load(f, strict=False)\n",
    "\n",
    "\n",
    "def dump_json_to_file(obj, filename, **kwargs):\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(obj, f, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video_dataset = load_json_from_file('train_dataset/info.json')\n",
    "video_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка видео ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка видео осуществляется при помощи cv2.VideoCapture. Этот код изменять и дописывать не нужно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret==False:\n",
    "            break\n",
    "        yield frame\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frames = read_video(os.path.join('train_dataset', 'video', '03.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что такое frames? Это итератор на кадры видео. Чтобы пройтись по всем кадрам последовательности, воспользуйтесь следующей конструкцией:\n",
    "*Аккуратно, по одной переменной frames можно пройти только один раз!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for frame in tqdm(frames):\n",
    "    pass\n",
    "for frame in tqdm(frames): # Второй раз уже не будет итерации\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пишем свой простой детектор смен сцен"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном этапе предлагается написать простой Scene Change Detector (SCD) на основе выделения характеристик кадров, подсчёта разницы между кадрами на основе данных характеристик, а также подобрать наиболее оптимальный порог для этих признаков и совместить эти признаки.\n",
    "Сменой сцен в данной задаче являются только обычные мгновенные смены сцен, без дополнительных эффектов.\n",
    "\n",
    "В качестве примера приведён простой детектор смен, который считает межкадровую разницу между кадрами.\n",
    "\n",
    "*Важное замечание. Здесь и далее результатом алгоритма детектора сцен являются **индексы кадров начал сцен**, при этом кадры **нумеруются с 0**. Нулевой кадр в качестве ответа указывать не нужно*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Hard_cut.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def baseline_scene_change_detector(frames, threshold=2000, with_vis=False):\n",
    "    \"\"\"\n",
    "    Baseline SCD\n",
    "\n",
    "    Arguments:\n",
    "    frames -- iterator on video frames\n",
    "    threshold -- parameter of your algorithm (optional)\n",
    "    with_vis -- saving neighboring frames at a scene change (optional)\n",
    "\n",
    "    Returns:\n",
    "    scene_changes -- list of scene changes (idx of frames)\n",
    "    vis -- list of neighboring frames at a scene change (for visualization)\n",
    "    metric_values -- list of metric values (for visualization)\n",
    "    \"\"\"\n",
    "    \n",
    "    def pixel_metric(frame, prev_frame):\n",
    "        # Базовое расстояние между кадрами - среднеквадратическая ошибка между ними\n",
    "        return np.mean((frame.astype(np.int32) - prev_frame) ** 2)\n",
    "\n",
    "    scene_changes = []\n",
    "    vis = []\n",
    "    metric_values = []\n",
    "    prev_frame = None\n",
    "    for idx, frame in tqdm(enumerate(frames), leave=False):\n",
    "        # frame - это кадр\n",
    "        # idx - это номер кадра\n",
    "        if prev_frame is not None:\n",
    "            # Находим расстояние между соседними кадрами\n",
    "            metric_value = pixel_metric(frame, prev_frame)\n",
    "            if metric_value > threshold:\n",
    "                scene_changes.append(idx)\n",
    "                if with_vis:\n",
    "                    # Кадры в памяти занимают много места, поэтому сохраним лишь первые 100 срабатываний\n",
    "                    if len(vis) < 100:\n",
    "                        vis.append([prev_frame, frame])\n",
    "            metric_values.append(metric_value)\n",
    "        else:\n",
    "            metric_values.append(0)\n",
    "        prev_frame = frame\n",
    "    return scene_changes, vis, metric_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# frames = read_video(os.path.join('train_dataset', 'video', '03.mp4'))\n",
    "# cuts_base = load_json_from_file(os.path.join('train_dataset', 'gt', '03.json'))['cut']\n",
    "# scene_changes_base, vis_base, metric_values_base = baseline_scene_change_detector(frames, with_vis=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим визуально, насколько сильно алгоритм ошибается, а также на значения метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def visualize_metric_error(frame, prev_frame, value):\n",
    "    fig = plt.figure(figsize=(16,4))\n",
    "    plt.suptitle('Значение метрики на текущем кадре: {:.4f}'.format(value[0]), fontsize=24)\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ax.imshow(prev_frame[:,:,::-1])\n",
    "    ax.set_title(\"Предыдущий кадр\", fontsize=18)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    ax.imshow(frame[:,:,::-1])\n",
    "    ax.set_title(\"Текущий кадр\", fontsize=18)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    plt.subplots_adjust(top=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = 1\n",
    "visualize_metric_error(vis_base[idx][0], vis_base[idx][1], metric_values_base[scene_changes_base[idx]])\n",
    "# смена сцен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = 10\n",
    "visualize_metric_error(vis_base[idx][0], vis_base[idx][1], metric_values_base[scene_changes_base[idx]])\n",
    "# ошибается, это не смена сцен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def visualize_metric_values(metric_values, threshold, thresh_values, scene_changes, cuts = None):\n",
    "    sns.set()\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.plot(metric_values, label='Значение метрики на кадрах')\n",
    "    plt.plot(thresh_values, label='Значение порога на кадрах')\n",
    "    plt.xlabel('Номер кадра')\n",
    "    plt.ylabel('Значение метрики')\n",
    "    plt.hlines(y=threshold, xmin=0, xmax=len(metric_values), linewidth=2, color='r', label='Пороговое значение')\n",
    "    \n",
    "    if cuts is not None:\n",
    "        for cut in cuts:\n",
    "            plt.axvline(x=cut, color='b', linestyle=':', linewidth=0.5, label='Смена сцены')\n",
    "    if scene_changes is not None:\n",
    "        for cut in scene_changes:\n",
    "            plt.axvline(x=cut, color='r', linestyle=':', linewidth=0.5, label='pred')\n",
    "\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    plt.legend(by_label.values(), by_label.keys())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_metric_values(metric_values_base, 2000, cuts_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как видим, очень плохо подобран порог, да и сам признак, похоже, сильно зашумлён. Попробуйте что-то своё!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваше решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* В качестве решения вы должны прикрепить функцию ниже. Все пороги должны быть указаны внутри функции.  \n",
    "Т.е. должен быть возможен вызов:  \n",
    "`scene_changes, vis, metric_values = scene_change_detector(frames)`  \n",
    "* Строку (# GRADED CELL: [function name]) менять **нельзя**. Она будет использоваться при проверке вашего решения.\n",
    "* Ячейка должна содержать только **одну** функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GRADED CELL: scene_change_detector\n",
    "# 0.6885444284792273 1000 1500 2500 1000\n",
    "def scene_change_detector(frames, w1_ = 1000, w2_ = 1500, w3_ = 2500, Threshold=1000, with_vis=False):\n",
    "    scene_changes = []\n",
    "    vis = []\n",
    "    metric_values = []\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    def get_brightness_hist(frame):\n",
    "        return cv2.calcHist([cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)], [0], None, [256], [0,256])\n",
    "    \n",
    "    def get_color_hist(frame):\n",
    "        color_hist = []\n",
    "        for i in range(3):\n",
    "            color_hist.append(cv2.calcHist([frame], [i], None, [256], [0, 256]))\n",
    "        return color_hist\n",
    "    \n",
    "    def pixel_metric(frame, prev_frame): #mse\n",
    "        return np.mean((frame.astype(np.int32) - prev_frame) ** 2)\n",
    "    \n",
    "    def abs_metric(frame, prev_frame):\n",
    "        return np.sum(np.absolute(frame.astype(np.int32)-prev_frame))\n",
    "    \n",
    "    def brightness_metric(frame_hist, prev_frame_hist):\n",
    "        return 1- (cv2.compareHist(prev_frame_hist, frame_hist, method=cv2.HISTCMP_CORREL)+1) / 2\n",
    "    \n",
    "    def color_metric(frame_color_hist, prev_frame_color_hist):      \n",
    "        color_values = np.zeros(3)\n",
    "        for i in range(3):\n",
    "            color_values[i] = (cv2.compareHist(prev_frame_color_hist[i], frame_color_hist[i], method=cv2.HISTCMP_CORREL)+1) / 2.0\n",
    "        return 1 - np.mean(color_values)\n",
    "            \n",
    "\n",
    "    def edge_metric(frame, prev_frame):\n",
    "        ddepth = cv2.CV_64F\n",
    "        gray1 = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray2 = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "        sobelx1 = cv2.Sobel(gray1, ddepth, 1, 0, ksize=5)\n",
    "        sobelx2 = cv2.Sobel(gray2, ddepth, 1, 0, ksize=5)\n",
    "        sobely1 = cv2.Sobel(gray1, ddepth, 0, 1, ksize=5)\n",
    "        sobely2 = cv2.Sobel(gray2, ddepth, 0, 1, ksize=5)\n",
    "        \n",
    "        diff_sobel_x = np.abs(sobelx1 - sobelx2)\n",
    "        diff_sobel_y = np.abs(sobely1 - sobely2)\n",
    "        diff_sobel = cv2.addWeighted(diff_sobel_x, 0.5, diff_sobel_y, 0.5, 0)\n",
    "        \n",
    "        mse = np.mean(diff_sobel)\n",
    "        return mse\n",
    "    def create_edge(frame):\n",
    "        gray1 = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        # Apply Gaussian blur to reduce noise and smoothen edges \n",
    "        blurred1 = cv2.GaussianBlur(src=gray1, ksize=(3, 5), sigmaX=0.5)\n",
    "        # Perform Canny edge detection \n",
    "        edges1 = cv2.Canny(blurred1, 70, 135)    \n",
    "        return edges1\n",
    "    def canny_edge(frame_edge, prev_frame_edge):\n",
    "        return np.mean((frame_edge.astype(np.int32)-prev_frame_edge)**2)\n",
    "        \n",
    "    # Ваши внешние переменные\n",
    "    w1 = w1_\n",
    "    w2=w2_\n",
    "    w3=w3_\n",
    "    # abs\n",
    "    a_abs = -1\n",
    "    b_abs = 4\n",
    "    c_abs = 4\n",
    "    window_abs = 5\n",
    "    abs_values = []\n",
    "    # mse\n",
    "    a_mse = -1\n",
    "    b_mse = 4\n",
    "    c_mse = 4\n",
    "    window_mse = 5\n",
    "    mse_values = []\n",
    "    # bright\n",
    "    a_bright = -1\n",
    "    b_bright = 15\n",
    "    c_bright = 15\n",
    "    window_bright = 15\n",
    "    bright_values = []\n",
    "    # color\n",
    "    a_color = -1\n",
    "    b_color = 15\n",
    "    c_color = 15\n",
    "    window_color = 15\n",
    "    color_values = []\n",
    "    # canny_edge\n",
    "    a_canny = -1\n",
    "    b_canny = 2\n",
    "    c_canny = 8\n",
    "    window_canny = 10\n",
    "    canny_values = []\n",
    "    \n",
    "    thresh_values = []\n",
    "    \n",
    "    OPENCV_METHODS = (\n",
    "\t(\"Correlation\", cv2.HISTCMP_CORREL),\n",
    "\t(\"Chi-Squared\", cv2.HISTCMP_CHISQR),\n",
    "\t(\"Intersection\", cv2.HISTCMP_INTERSECT),\n",
    "\t(\"Hellinger\", cv2.HISTCMP_BHATTACHARYYA))\n",
    "    prev_frame = None\n",
    "    prev_frame_hist = None\n",
    "    prev_frame_color_hist = None\n",
    "    prev_frame_edge = None\n",
    "    mse_value = hist_value = color_value = edge_value = 0\n",
    "    metrics = [\n",
    "        [mse_value, 0.2],\n",
    "        [hist_value, 0.35],\n",
    "        [color_value, 0.375],\n",
    "        [edge_value, 0.1]\n",
    "    ]\n",
    "    ###  END CODE HERE  ###\n",
    "    \n",
    "    for idx, frame in tqdm(enumerate(frames), leave=False):\n",
    "        # frame - это кадр\n",
    "        # idx - это номер кадра\n",
    "        ### START CODE HERE ###\n",
    "        # Основная часть вашего алгоритма\n",
    "        metric_value = 0\n",
    "        if prev_frame is not None:\n",
    "            metrics = []\n",
    "            # MSE\n",
    "            \n",
    "            mse_value = pixel_metric(frame, prev_frame)\n",
    "            m = np.mean(mse_values[max(idx-window_mse, 0):idx])\n",
    "            std = np.std(mse_values[max(idx-window_mse, 0):idx])\n",
    "            mse_thresh = a_mse*mse_values[-1]+b_mse*m+std*c_mse\n",
    "            mse_values.append(mse_value)\n",
    "            metrics.append((mse_value, mse_thresh))\n",
    "            \n",
    "            \n",
    "            # ABS\n",
    "            \n",
    "            abs_value = abs_metric(frame, prev_frame)\n",
    "            m = np.mean(abs_values[max(idx-window_abs, 0):idx])\n",
    "            std = np.std(abs_values[max(idx-window_abs, 0):idx])\n",
    "            abs_thresh = a_abs*abs_values[-1]+b_abs*m+std*c_abs\n",
    "            abs_values.append(abs_value)\n",
    "            metrics.append((abs_value, abs_thresh))\n",
    "            \n",
    "            # BRIGHTNESSS\n",
    "            #save histogram of previous frame\n",
    "            \n",
    "            frame_hist = get_brightness_hist(frame)\n",
    "            if prev_frame_hist is None:\n",
    "                prev_frame_hist = get_brightness_hist(prev_frame)\n",
    "            bright_value = brightness_metric(frame_hist, prev_frame_hist)\n",
    "            prev_frame_hist = frame_hist\n",
    "            m = np.mean(bright_values[max(idx-window_bright, 0):idx])\n",
    "            std = np.std(bright_values[max(idx-window_bright, 0):idx])\n",
    "            bright_thresh = a_bright*bright_values[-1]+b_bright*m+std*c_bright\n",
    "            bright_values.append(bright_value)\n",
    "            metrics.append((bright_value, bright_thresh))\n",
    "            \n",
    "            \n",
    "            # COLOR\n",
    "            #save histogram of previous frame\n",
    "            \n",
    "            frame_color_hist = get_color_hist(frame)\n",
    "            if prev_frame_color_hist is None:\n",
    "                prev_frame_color_hist = get_color_hist(prev_frame)\n",
    "            color_value = color_metric(frame_color_hist, prev_frame_color_hist)\n",
    "            prev_frame_color_hist = frame_color_hist\n",
    "            m = np.mean(color_values[max(idx-window_color, 0):idx])\n",
    "            std = np.std(color_values[max(idx-window_color, 0):idx])\n",
    "            color_thresh = a_color*color_values[-1]+b_color*m+std*c_color\n",
    "            color_values.append(color_value)\n",
    "            metrics.append((color_value, color_thresh))\n",
    "            \n",
    "            \n",
    "            # CANNY EDGE DETECTION\n",
    "            \n",
    "            frame_edge = create_edge(frame)\n",
    "            if prev_frame_edge is None:\n",
    "                prev_frame_edge = create_edge(prev_frame)\n",
    "            canny_edge_value = canny_edge(frame_edge, prev_frame_edge)\n",
    "            m = np.mean(canny_values[max(idx-window_canny, 0):idx])\n",
    "            std = np.std(canny_values[max(idx-window_canny, 0):idx])\n",
    "            canny_thresh = a_canny*canny_values[-1]+b_canny*m+std*c_canny\n",
    "            canny_values.append(canny_edge_value)\n",
    "            metrics.append((canny_edge_value, canny_thresh))\n",
    "            \n",
    "\n",
    "            # #sliding window with metric values\n",
    "            # values[:-1] = values[1:]\n",
    "            # values[-1] = metric_value  \n",
    "              \n",
    "            #voting by majority\n",
    "            votes = 0\n",
    "            if color_value>color_thresh:\n",
    "                votes+=2\n",
    "            if bright_value>bright_thresh:\n",
    "                votes+=1\n",
    "            if mse_value>mse_thresh:\n",
    "                votes+=1\n",
    "            if abs_value>abs_thresh:\n",
    "                votes+=1\n",
    "            if canny_edge_value>canny_thresh:\n",
    "                votes+=1\n",
    "            if votes>=4 and idx>2:  \n",
    "                scene_changes.append(idx)\n",
    "                if with_vis:\n",
    "                    # Кадры в памяти занимают много места, поэтому сохраним лишь первые 100 срабатываний\n",
    "                    if len(vis) < 100:\n",
    "                        vis.append([prev_frame, frame])\n",
    "            metric_values.append([abs_value, mse_value, bright_value, color_value, canny_edge_value])\n",
    "        else:\n",
    "            metric_values.append([0,0,0,0,0])\n",
    "            mse_values.append(0)\n",
    "            mse_values.append(0)\n",
    "            abs_values.append(0)\n",
    "            canny_values.append(0)\n",
    "            bright_values.append(0)\n",
    "            color_values.append(0)\n",
    "        prev_frame = frame\n",
    "\n",
    "     \n",
    "         \n",
    "        ###  END CODE HERE  ###\n",
    "\n",
    "    return scene_changes, vis, metric_values, thresh_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frames = read_video(os.path.join('train_dataset', 'video', '100.mp4'))\n",
    "cuts = load_json_from_file(os.path.join('train_dataset', 'gt', '05.json'))['cut']\n",
    "scene_changes, vis, metric_values, thresh_values = scene_change_detector(frames, with_vis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обратите внимание на скорость работы алгоритма! ####\n",
    "Если вычислять признаки без циклов по пикселям, а пользоваться методами из numpy, то скорость будет не медленнее 7-8 кадров в секунду.\n",
    "Например, вы можете использовать функцию `np.histogram` или `cv2.calcHist` для подсчёта гистограмм, а `cv2.Sobel` для применения оператора Собеля к кадру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Посмотрим на найденные смены сцен\n",
    "idx = -18\n",
    "visualize_metric_error(vis[idx][0], vis[idx][1], metric_values[scene_changes[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cuts)\n",
    "print(scene_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Посмотрим на значения метрики\n",
    "visualize_metric_values(metric_values, 0, thresh_values, scene_changes, cuts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подсчёт метрики F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы оценивать алгоритм и научиться сравнивать несколько алгоритмов, нужна метрика качества. В данной задаче для оценки качества алгоритма используется F1-Score. Преимущества использования этой метрики к текущей постановке задачи смены сцен были рассказаны на лекции, напишем только формулы:\n",
    "$$precision = \\frac{tp}{tp+fp}$$\n",
    "$$recall = \\frac{tp}{tp+fn}$$\n",
    "$$F = 2 * \\frac{precision * recall}{precision+recall}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На всякий случай опишем как именно происходит подсчёт метрики для видео\n",
    "\n",
    "1) Сначала из выборки удаляются все кадры, которые по разметке либо являются сложными переходами между сценами, либо помечены как сложные для анализа и разметки (например, титры/обилие компьютерной графики и т.п)\n",
    "\n",
    "\n",
    "2) Затем для оставшихся кадров уже подсчитывается F1_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Эти пять клеток кода править не нужно\n",
    "def calculate_matrix(true_scd, predicted_scd, scene_len, not_to_use_frames=set()):\n",
    "    predicted_scd = set(predicted_scd)\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    scene_len = scene_len\n",
    "    for scd in predicted_scd:\n",
    "        if scd in true_scd:\n",
    "            tp += 1\n",
    "        elif scd not in not_to_use_frames:\n",
    "            fp += 1\n",
    "    for scd in true_scd:\n",
    "        if scd not in predicted_scd:\n",
    "            fn += 1\n",
    "    tn = scene_len - len(not_to_use_frames) - tp - fp - fn\n",
    "    return tp, fp, tn, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_precision(tp, fp, tn, fn):\n",
    "    return tp / max(1, (tp + fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_recall(tp, fp, tn, fn):\n",
    "    return tp / max(1, (tp + fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f1_score(true_scd, predicted_scd, scene_len, not_to_use_frames=set()):\n",
    "    tp, fp, tn, fn = calculate_matrix(true_scd, predicted_scd, scene_len, not_to_use_frames)\n",
    "    precision_score = calculate_precision(tp, fp, tn, fn)\n",
    "    recall_score = calculate_recall(tp, fp, tn, fn)\n",
    "    if precision_score + recall_score == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2 * precision_score * recall_score / (precision_score + recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f1_score_matrix(tp, fp, tn, fn):\n",
    "    precision_score = calculate_precision(tp, fp, tn, fn)\n",
    "    recall_score = calculate_recall(tp, fp, tn, fn)\n",
    "    if precision_score + recall_score == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2 * precision_score * recall_score / (precision_score + recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестируем разработанный метод сразу на нескольких видео "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, насколько хорошо работает разработанный метод. *Учтите, что итоговое тестирование будет производиться на аналогичном, но недоступном вам наборе видео, но все параметры алгоритмов должны быть указаны вами (иными словами - подобраны на тренировочном наборе).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_scene_change_detector_all_video(scene_change_detector, dataset_path):\n",
    "    video_dataset = load_json_from_file(os.path.join(dataset_path, 'info.json'))\n",
    "    param_log = {\n",
    "        '_mean_f1_score': []\n",
    "    }\n",
    "    for video_info in tqdm(video_dataset, leave=False):\n",
    "        # Загружаем видео, его длину и смены сцен\n",
    "        frames = read_video(os.path.join(dataset_path, video_info['source']))\n",
    "        video_len = video_info['len']\n",
    "        true_scene_changes = load_json_from_file(os.path.join(dataset_path, video_info['scene_change']))\n",
    "        \n",
    "        # Составляем список сцен, которые не будут тестироваться\n",
    "        not_use_frames = set()\n",
    "        for type_scene_change in ['trash', 'fade', 'dissolve']:\n",
    "            for bad_scene_range in true_scene_changes.get(type_scene_change, []):\n",
    "                not_use_frames.update(list(range(bad_scene_range[0], bad_scene_range[1] + 1)))\n",
    "        \n",
    "        predicted_scene_changes, _, _ = scene_change_detector(frames)\n",
    "        \n",
    "        param_log['f1_score_{}'.format(video_info['source'])] = f1_score(\n",
    "            true_scene_changes['cut'],\n",
    "            predicted_scene_changes,\n",
    "            video_len,\n",
    "            not_use_frames\n",
    "        )\n",
    "        video_tp, video_fp, video_tn, video_fn = calculate_matrix(\n",
    "            true_scene_changes['cut'],\n",
    "            predicted_scene_changes,\n",
    "            video_len,\n",
    "            not_use_frames\n",
    "        )\n",
    "        \n",
    "        param_log['tp_{}'.format(video_info['source'])] = video_tp\n",
    "        param_log['fp_{}'.format(video_info['source'])] = video_fp\n",
    "        param_log['tn_{}'.format(video_info['source'])] = video_tn\n",
    "        param_log['fn_{}'.format(video_info['source'])] = video_fn \n",
    "        param_log['_mean_f1_score'].append(param_log['f1_score_{}'.format(video_info['source'])])\n",
    "    param_log['_mean_f1_score'] = np.mean(param_log['_mean_f1_score'])\n",
    "    return param_log, param_log['_mean_f1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video_dataset = 'train_dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная функция поможет вам посмотреть, на каких видео и на сколько ошибается ваш метод. Прогнать метод на отдельном видео и детально посмотреть кадры вы могли выше.\n",
    "\n",
    "Кроме того, с помощью этой функции вы можете подобрать оптимальные параметры для метода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Протестируем базовый метод\n",
    "run_scene_change_detector_all_video(baseline_scene_change_detector, video_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Протестируем разработанный вами метод\n",
    "run_scene_change_detector_all_video(scene_change_detector, video_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = [1000, 2000, 3000]\n",
    "w2 = [500, 1500, 2500]\n",
    "w3 = [500, 1500, 2500]\n",
    "threshold = [500, 750, 1000]\n",
    "\n",
    "for w1_ in w1:\n",
    "    for w2_ in w2:\n",
    "        for w3_ in w3:\n",
    "            for thresh_ in threshold:\n",
    "                _, score = run_scene_change_detector_all_video(scene_change_detector, video_dataset, w1_,w2_,w3_,thresh_)\n",
    "                print(score, w1_,w2_, w3_,thresh_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда вы смотрите на результат, обращайте внимание на **_mean_f1_score**  \n",
    "Именно по этой метрике будет производится финальное оценивание."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бонусное задание: распознавание смен сцен типа \"наложения\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На практике кроме катов часто встречаются смены сцен, где происходит \"наложение\" одной сцены на другую:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Dissolve.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваше решение "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* В качестве решения вы должны прикрепить функцию ниже. Все пороги должны быть указаны внутри функции.  \n",
    "Т.е. должен быть возможен вызов:  \n",
    "`scene_changes, vis, metric_values = scene_change_detector_dissolve(frames)`  \n",
    "* Строку (# GRADED CELL: [function name]) менять **нельзя**. Она будет использоваться при проверке вашего решения.\n",
    "* Ячейка должна содержать только **одну** функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GRADED CELL: scene_change_detector_dissolve\n",
    "# 0.6885444284792273 1000 1500 2500 1000\n",
    "def scene_change_detector_dissolve(frames, w1_=1000, w2_=1500, w3_=2500, Threshold=200, with_vis=False):\n",
    "    scene_changes = []\n",
    "    vis = []\n",
    "    metric_values = []\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    def pixel_metric(frame, prev_frame):  # mse\n",
    "        return np.mean((frame.astype(np.int32) - prev_frame) ** 2)\n",
    "\n",
    "    def pixel_metric_normalized(frame, prev_frame):\n",
    "        # / pixel_metric(np.full_like(frame, 255),0)\n",
    "        return pixel_metric(frame, prev_frame) * 0.00004\n",
    "\n",
    "    def brightness_metric(frame, prev_frame):\n",
    "        frame_hist = cv2.calcHist(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), [\n",
    "                                  0], None, [25], [0, 255])\n",
    "        prev_frame_hist = cv2.calcHist(cv2.cvtColor(\n",
    "            prev_frame, cv2.COLOR_BGR2GRAY), [0], None, [25], [0, 255])\n",
    "        hist_value = max(cv2.compareHist(\n",
    "            prev_frame_hist, frame_hist, method=cv2.HISTCMP_BHATTACHARYYA), 0)\n",
    "        return hist_value\n",
    "\n",
    "    def color_metric(frame, prev_frame):\n",
    "        color_values = np.zeros(3)\n",
    "        for i in range(3):\n",
    "            frame_hist = cv2.calcHist(frame, [i], None, [25], [0, 255])\n",
    "            prev_frame_hist = cv2.calcHist(\n",
    "                prev_frame, [i], None, [25], [0, 255])\n",
    "            color_values[i] = max(cv2.compareHist(\n",
    "                prev_frame_hist, frame_hist, method=cv2.HISTCMP_CORREL), 0)\n",
    "        return 1 - np.max(color_values)\n",
    "\n",
    "    def edge_metric(frame, prev_frame):\n",
    "        ddepth = cv2.CV_64F\n",
    "        gray1 = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray2 = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "        sobelx1 = cv2.Sobel(gray1, ddepth, 1, 0, ksize=5)\n",
    "        sobelx2 = cv2.Sobel(gray2, ddepth, 1, 0, ksize=5)\n",
    "        sobely1 = cv2.Sobel(gray1, ddepth, 0, 1, ksize=5)\n",
    "        sobely2 = cv2.Sobel(gray2, ddepth, 0, 1, ksize=5)\n",
    "\n",
    "        diff_sobel_x = np.abs(sobelx1 - sobelx2)\n",
    "        diff_sobel_y = np.abs(sobely1 - sobely2)\n",
    "        diff_sobel = cv2.addWeighted(diff_sobel_x, 0.5, diff_sobel_y, 0.5, 0)\n",
    "\n",
    "        mse = np.mean(diff_sobel)\n",
    "        height, width = frame.shape[:2]\n",
    "        # print(height, width)\n",
    "        return mse / (height*width)\n",
    "\n",
    "    # Ваши внешние переменные\n",
    "    w1 = w1_\n",
    "    w2 = w2_\n",
    "    w3 = w3_\n",
    "    OPENCV_METHODS = (\n",
    "\t(\"Correlation\", cv2.HISTCMP_CORREL),\n",
    "\t(\"Chi-Squared\", cv2.HISTCMP_CHISQR),\n",
    "\t(\"Intersection\", cv2.HISTCMP_INTERSECT),\n",
    "\t(\"Hellinger\", cv2.HISTCMP_BHATTACHARYYA))\n",
    "    prev_frame = None\n",
    "    prev_prev_frame = None\n",
    "    mse_thresh = 0.03\n",
    "    ###  END CODE HERE  ###\n",
    "\n",
    "    for idx, frame in tqdm(enumerate(frames), leave=False):\n",
    "        # frame - это кадр\n",
    "        # idx - это номер кадра\n",
    "        ### START CODE HERE ###\n",
    "        # Основная часть вашего алгоритма\n",
    "        if prev_frame is not None:\n",
    "            if prev_prev_frame is not None:\n",
    "                # mse\n",
    "                # mse_value = pixel_metric_normalized(frame, prev_frame)\n",
    "                # # histograms\n",
    "                # hist_value = brightness_metric(frame, prev_frame)\n",
    "                # color_value = color_metric(frame, prev_frame)\n",
    "                # sobel\n",
    "                # edge_value = edge_metric(frame, prev_frame)\n",
    "                # weights\n",
    "                # w = 1000\n",
    "                w1 = 2000\n",
    "                # w2 = 1500\n",
    "                # w3 = 1000\n",
    "                # w4 = 10000 #lol\n",
    "                # if (mse_value <= mse_thresh):\n",
    "                #     hist_value = 0\n",
    "                #     color_value = 0\n",
    "                sum = cv2.addWeighted(frame, 0.5, prev_prev_frame, 0.5, 0)\n",
    "                \n",
    "                metric_value = pixel_metric_normalized(sum, prev_frame)*w1\n",
    "                if metric_value > Threshold:\n",
    "                    scene_changes.append(idx)\n",
    "                    if with_vis:\n",
    "                        # Кадры в памяти занимают много места, поэтому сохраним лишь первые 100 срабатываний\n",
    "                        if len(vis) < 100:\n",
    "                            vis.append([prev_frame, frame])\n",
    "                metric_values.append(metric_value)\n",
    "            else:\n",
    "                metric_values.append(0)\n",
    "            prev_prev_frame = prev_frame\n",
    "        prev_frame = frame\n",
    "\n",
    "        ###  END CODE HERE  ###\n",
    "\n",
    "    return scene_changes, vis, metric_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = read_video(os.path.join('train_dataset', 'video', '03.mp4'))\n",
    "cuts = load_json_from_file(os.path.join('train_dataset', 'gt', '03.json'))['dissolve']\n",
    "scene_changes, vis, metric_values = scene_change_detector_dissolve(frames, with_vis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Посмотрим на найденные смены сцен\n",
    "idx = 3\n",
    "visualize_metric_error(vis[idx][0], vis[idx][1], metric_values[scene_changes[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Посмотрим на значения метрики\n",
    "visualize_metric_values(metric_values, 750, cuts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве метрики качества используется видоизменённый f1-score:\n",
    "\n",
    "Так как смена сцен не происходит за один кадр, попаданием считается попадание ответа смены сцен в отрезок, где происходит наложение.  \n",
    "**Обратите внимание**, что несколько раз указывать одну смену сцен не нужно.\n",
    "\n",
    "Попадание вне отрезков смен сцен путём наложения считается как false positive, не попадание в указанный отрезок - как false negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Эти три клетки кода править не нужно\n",
    "def calculate_matrix_dissolve(true_scd, predicted_scd, scene_len):\n",
    "    predicted_scd = set(predicted_scd)\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    scene_len = scene_len\n",
    "    checked_dissolve_segments = set()\n",
    "    total_scene_dissolve_len = np.sum([dissolve_segment[1] - dissolve_segment[0] + 1 for dissolve_segment in true_scd])\n",
    "    for scd in predicted_scd:\n",
    "        for dissolve_segment in true_scd:\n",
    "            if scd in range(dissolve_segment[0], dissolve_segment[1] + 1):\n",
    "                if tuple(dissolve_segment) not in checked_dissolve_segments:\n",
    "                    tp += 1\n",
    "                    checked_dissolve_segments.add(tuple(dissolve_segment))\n",
    "                break\n",
    "        else:\n",
    "            fp += 1\n",
    "    fn = len(true_scd) - len(checked_dissolve_segments)\n",
    "    tn = scene_len - total_scene_dissolve_len + len(true_scd) - tp - fp - fn\n",
    "    return tp, fp, tn, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f1_score_dissolve(true_scd, predicted_scd, scene_len):\n",
    "    tp, fp, tn, fn = calculate_matrix_dissolve(true_scd, predicted_scd, scene_len)\n",
    "    precision_score = calculate_precision(tp, fp, tn, fn)\n",
    "    recall_score = calculate_recall(tp, fp, tn, fn)\n",
    "    if precision_score + recall_score == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2 * precision_score * recall_score / (precision_score + recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_scene_change_detector_all_video_dissolve(scene_change_detector, dataset_path):\n",
    "    video_dataset = load_json_from_file(os.path.join(dataset_path, 'info.json'))\n",
    "    param_log = {\n",
    "        '_mean_f1_score': []\n",
    "    }\n",
    "    for video_info in tqdm(video_dataset, leave=False):\n",
    "        frames = read_video(os.path.join(dataset_path, video_info['source']))\n",
    "        video_len = video_info['len']\n",
    "        true_scene_changes = load_json_from_file(os.path.join(dataset_path, video_info['scene_change']))\n",
    "        \n",
    "        predicted_scene_changes, _, _ = scene_change_detector(frames)\n",
    "        param_log['f1_score_{}'.format(video_info['source'])] = f1_score_dissolve(\n",
    "            true_scene_changes.get('dissolve', []),\n",
    "            predicted_scene_changes,\n",
    "            video_len\n",
    "        )\n",
    "        video_tp, video_fp, video_tn, video_fn = calculate_matrix_dissolve(\n",
    "            true_scene_changes.get('dissolve', []),\n",
    "            predicted_scene_changes,\n",
    "            video_len\n",
    "        )\n",
    "        param_log['tp_{}'.format(video_info['source'])] = video_tp\n",
    "        param_log['fp_{}'.format(video_info['source'])] = video_fp\n",
    "        param_log['tn_{}'.format(video_info['source'])] = video_tn\n",
    "        param_log['fn_{}'.format(video_info['source'])] = video_fn\n",
    "        param_log['_mean_f1_score'].append(param_log['f1_score_{}'.format(video_info['source'])])\n",
    "    param_log['_mean_f1_score'] = np.mean(param_log['_mean_f1_score'])\n",
    "    return param_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video_dataset_path = 'train_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Протестируем разработанный вами метод\n",
    "run_scene_change_detector_all_video_dissolve(scene_change_detector_dissolve, video_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Немного об оценивании задания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценивание задания будет производиться по следующей схеме:  \n",
    "\n",
    "Пусть на скрытой выборке по F-метрике вы получили X, лучшее решение получило Y.\n",
    "\n",
    "1. Базовая часть оценивется как $$20 * \\left(\\frac{\\max(0, X_{base} - 0.5)}{Y_{base} - 0.5}\\right)^2 + Bonus_{base}$$ Бонусные баллы $Bonus$ можно получить за оригинальные идеи в задаче или в её реализации\n",
    "2. Дополнительное задание оценивается как $$5 * \\frac{\\max(0, X_{add} - 0.1)}{Y_{add} - 0.1} + Bonus_{add}$$Процесс получения бонусных баллов аналогичен получению бонусных баллов в базовой части"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваши ощущения ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*До дедлайна пару часов и вы никак не можете улучшить текущее решение? Или наоборот, вы всё сделали очень быстро? Опишите кратко ваши ощущения от задания - сколько времени вы потратили на задание, сколько вы потратили на изучение питона и установку необходимых библиотек, как быстро вы придумывали новые идеи и как они давали прирост по метрике и в целом насколько это задание вам понравилось и что хотели бы изменить/добавить.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='second'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2. Scene change detector. Машинное обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Внимание!**\n",
    "\n",
    "В этом задании можно использовать все, что разрешалось в Задании №1, а также библиотеки:\n",
    "* pandas\n",
    "* sklearn\n",
    "\n",
    "Большинство функций, использующихся в этом задании, реализованы выше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Бейзлайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим простой SVM классификатор над метрикой попиксельной разницы кадров на нескольких видео. Воспользуемся функцией из первого задания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(train_videos):\n",
    "    X_train, y_train = None, np.array([])\n",
    "    for video in train_videos:\n",
    "        frames = read_video(os.path.join('train_dataset', 'video', f'{video}.mp4'))\n",
    "        # baseline функция попиксельного сравнения кадров из прошлого задания\n",
    "        # нам нужны не сами смены сцен, а только значения метрик\n",
    "        cuts, _, metric_values = scene_change_detector(frames) \n",
    "        \n",
    "        video_scenes = np.array([0 for i in range(len(metric_values))])\n",
    "        video_scenes[cuts] += 1\n",
    "        \n",
    "        # добавляем в разметку текущее видео\n",
    "        if X_train is None:\n",
    "            X_train = metric_values\n",
    "        else:\n",
    "            X_train = np.concatenate((X_train, metric_values),0)\n",
    "        y_train = np.hstack((y_train, video_scenes))\n",
    "        \n",
    "    return X_train, y_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [[0,0,0,0,0],[0,0,0,0,0]]\n",
    "B = [[0,0,0,0,0],[0,0,0,0,0]]\n",
    "np.concatenate((A,B),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_videos = ['04', '05']\n",
    "\n",
    "X_train, y_train = get_train_data(train_videos)\n",
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание модели\n",
    "# подберите лучшие параметры для данной задачи\n",
    "params = {\"kernel\": \"rbf\", \"C\": 1}\n",
    "model = SVC(**params)\n",
    "model.fit(X_train.reshape(-1, 1), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Сохраним модель в файле *model.pkl*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open(\"model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим как модель работает на тестовых видео\n",
    "\n",
    "Обратите внимание на то, что внутри функции модель загружается из памяти из файла *model.pkl*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_scene_change_detection_ml(frames):\n",
    "    # подготавливаем данные для видео\n",
    "    _, _, metric_values = baseline_scene_change_detector(frames) \n",
    "    X_test = np.array(metric_values).reshape(-1, 1)\n",
    "    # загружаем модель и делаем предсказания\n",
    "    model = pickle.load(open(\"model.pkl\", 'rb')) \n",
    "    predict_cuts = model.predict(X_test)\n",
    "    \n",
    "    return np.where(predict_cuts > 0)[0], [], metric_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scene_change_detector_ml_one_video(scene_change_detector, dataset_path, video_num):\n",
    "    video_info = load_json_from_file(os.path.join(dataset_path, 'info.json'))[video_num]\n",
    "    \n",
    "    # Загружаем видео, его длину и смены сцен\n",
    "    frames = read_video(os.path.join(dataset_path, video_info['source']))\n",
    "    video_len = video_info['len']\n",
    "    true_scene_changes = load_json_from_file(os.path.join(dataset_path, video_info['scene_change']))\n",
    "\n",
    "    # Составляем список сцен, которые не будут тестироваться\n",
    "    not_use_frames = set()\n",
    "    for type_scene_change in ['trash', 'fade', 'dissolve']:\n",
    "        for bad_scene_range in true_scene_changes.get(type_scene_change, []):\n",
    "            not_use_frames.update(list(range(bad_scene_range[0], bad_scene_range[1] + 1)))\n",
    "\n",
    "    predicted_scene_changes, _, _ = scene_change_detector(frames)\n",
    "\n",
    "    return f1_score(\n",
    "        true_scene_changes['cut'],\n",
    "        predicted_scene_changes,\n",
    "        video_len,\n",
    "        not_use_frames\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем F1 score для одного видео:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_num = 1\n",
    "run_scene_change_detector_ml_one_video(baseline_scene_change_detection_ml, 'train_dataset', video_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_scene_change_detector_all_video(baseline_scene_change_detection_ml, video_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваше решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы использовать свою обученную модель при отправке решения, необходимо сохранить ее через пакет pickle в файл model.pkl и отправить его вместе с jupyter ноутбуком.\n",
    "Этот файл вы можете открывать и использовать прямо в функции вашего решения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* В качестве решения вы должны прикрепить функцию ниже. Все пороги должны быть указаны внутри функции.  \n",
    "Т.е. должен быть возможен вызов:  \n",
    "`scene_changes, vis, metric_values = scene_change_detector_dissolve(frames)`  \n",
    "* Строку (# GRADED CELL: [function name]) менять **нельзя**. Она будет использоваться при проверке вашего решения.\n",
    "* Ячейка должна содержать только **одну** функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# GRADED CELL: scene_change_detector_ml\n",
    "\n",
    "def scene_change_detector_ml(frames, with_vis = False):\n",
    "    scene_changes = []\n",
    "    vis = []\n",
    "    metric_values = []\n",
    "    \n",
    "    ###\n",
    "    def get_brightness_hist(frame):\n",
    "        return cv2.calcHist([cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)], [0], None, [256], [0,256])\n",
    "    \n",
    "    def get_color_hist(frame):\n",
    "        color_hist = []\n",
    "        for i in range(3):\n",
    "            color_hist.append(cv2.calcHist([frame], [i], None, [256], [0, 256]))\n",
    "        return color_hist\n",
    "    \n",
    "    def pixel_metric(frame, prev_frame): #mse\n",
    "        return np.mean((frame.astype(np.int32) - prev_frame) ** 2)\n",
    "    \n",
    "    def abs_metric(frame, prev_frame):\n",
    "        return np.sum(np.absolute(frame.astype(np.int32)-prev_frame))\n",
    "    \n",
    "    def brightness_metric(frame_hist, prev_frame_hist):\n",
    "        return 1- (cv2.compareHist(prev_frame_hist, frame_hist, method=cv2.HISTCMP_CORREL)+1) / 2\n",
    "    \n",
    "    def color_metric(frame_color_hist, prev_frame_color_hist):      \n",
    "        color_values = np.zeros(3)\n",
    "        for i in range(3):\n",
    "            color_values[i] = (cv2.compareHist(prev_frame_color_hist[i], frame_color_hist[i], method=cv2.HISTCMP_CORREL)+1) / 2.0\n",
    "        return 1 - np.mean(color_values)\n",
    "    def create_edge(frame):\n",
    "        gray1 = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        # Apply Gaussian blur to reduce noise and smoothen edges \n",
    "        blurred1 = cv2.GaussianBlur(src=gray1, ksize=(3, 5), sigmaX=0.5)\n",
    "        # Perform Canny edge detection \n",
    "        edges1 = cv2.Canny(blurred1, 70, 135)    \n",
    "        return edges1\n",
    "    def canny_edge(frame_edge, prev_frame_edge):\n",
    "        return np.mean((frame_edge.astype(np.int32)-prev_frame_edge)**2)      \n",
    "    ###\n",
    "    \n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Ваши внешние переменные\n",
    "    # abs\n",
    "    a_abs = -1\n",
    "    b_abs = 4\n",
    "    c_abs = 4\n",
    "    window_abs = 5\n",
    "    abs_values = []\n",
    "    # mse\n",
    "    a_mse = -1\n",
    "    b_mse = 4\n",
    "    c_mse = 4\n",
    "    window_mse = 5\n",
    "    mse_values = []\n",
    "    # bright\n",
    "    a_bright = -1\n",
    "    b_bright = 15\n",
    "    c_bright = 15\n",
    "    window_bright = 15\n",
    "    bright_values = []\n",
    "    # color\n",
    "    a_color = -1\n",
    "    b_color = 15\n",
    "    c_color = 15\n",
    "    window_color = 15\n",
    "    color_values = []\n",
    "    # canny_edge\n",
    "    a_canny = -1\n",
    "    b_canny = 2\n",
    "    c_canny = 8\n",
    "    window_canny = 10\n",
    "    canny_values = []\n",
    "    metrics=[]\n",
    "    prev_frame = None\n",
    "    prev_frame_hist = None\n",
    "    prev_frame_color_hist = None\n",
    "    prev_frame_edge = None\n",
    "    mse_value = hist_value = color_value = edge_value = 0\n",
    "    ###  END CODE HERE  ###\n",
    "    \n",
    "    for idx, frame in tqdm(enumerate(frames), leave=False):\n",
    "        # frame - это кадр\n",
    "        # idx - это номер кадра\n",
    "        \n",
    "        ### START CODE HERE ###\n",
    "        # Основная часть вашего алгоритма\n",
    "        # COLOR\n",
    "        #save histogram of previous frame\n",
    "        if prev_frame is not None:\n",
    "            metrics = []\n",
    "            # MSE\n",
    "            \n",
    "            mse_value = pixel_metric(frame, prev_frame)\n",
    "            m = np.mean(mse_values[max(idx-window_mse, 0):idx])\n",
    "            std = np.std(mse_values[max(idx-window_mse, 0):idx])\n",
    "            mse_thresh = a_mse*mse_values[-1]+b_mse*m+std*c_mse\n",
    "            mse_values.append(mse_value)\n",
    "            metrics.append((mse_value, mse_thresh))\n",
    "            \n",
    "            \n",
    "            # ABS\n",
    "            \n",
    "            abs_value = abs_metric(frame, prev_frame)\n",
    "            m = np.mean(abs_values[max(idx-window_abs, 0):idx])\n",
    "            std = np.std(abs_values[max(idx-window_abs, 0):idx])\n",
    "            abs_thresh = a_abs*abs_values[-1]+b_abs*m+std*c_abs\n",
    "            abs_values.append(abs_value)\n",
    "            metrics.append((abs_value, abs_thresh))\n",
    "            \n",
    "            # BRIGHTNESSS\n",
    "            #save histogram of previous frame\n",
    "            \n",
    "            frame_hist = get_brightness_hist(frame)\n",
    "            if prev_frame_hist is None:\n",
    "                prev_frame_hist = get_brightness_hist(prev_frame)\n",
    "            bright_value = brightness_metric(frame_hist, prev_frame_hist)\n",
    "            prev_frame_hist = frame_hist\n",
    "            m = np.mean(bright_values[max(idx-window_bright, 0):idx])\n",
    "            std = np.std(bright_values[max(idx-window_bright, 0):idx])\n",
    "            bright_thresh = a_bright*bright_values[-1]+b_bright*m+std*c_bright\n",
    "            bright_values.append(bright_value)\n",
    "            metrics.append((bright_value, bright_thresh))\n",
    "            \n",
    "            \n",
    "            # COLOR\n",
    "            #save histogram of previous frame\n",
    "            \n",
    "            frame_color_hist = get_color_hist(frame)\n",
    "            if prev_frame_color_hist is None:\n",
    "                prev_frame_color_hist = get_color_hist(prev_frame)\n",
    "            color_value = color_metric(frame_color_hist, prev_frame_color_hist)\n",
    "            prev_frame_color_hist = frame_color_hist\n",
    "            m = np.mean(color_values[max(idx-window_color, 0):idx])\n",
    "            std = np.std(color_values[max(idx-window_color, 0):idx])\n",
    "            color_thresh = a_color*color_values[-1]+b_color*m+std*c_color\n",
    "            color_values.append(color_value)\n",
    "            metrics.append((color_value, color_thresh))\n",
    "            \n",
    "            \n",
    "            # CANNY EDGE DETECTION\n",
    "            \n",
    "            frame_edge = create_edge(frame)\n",
    "            if prev_frame_edge is None:\n",
    "                prev_frame_edge = create_edge(prev_frame)\n",
    "            canny_edge_value = canny_edge(frame_edge, prev_frame_edge)\n",
    "            m = np.mean(canny_values[max(idx-window_canny, 0):idx])\n",
    "            std = np.std(canny_values[max(idx-window_canny, 0):idx])\n",
    "            canny_thresh = a_canny*canny_values[-1]+b_canny*m+std*c_canny\n",
    "            canny_values.append(canny_edge_value)\n",
    "            metrics.append((canny_edge_value, canny_thresh))\n",
    "            \n",
    "\n",
    "            # #sliding window with metric values\n",
    "            # values[:-1] = values[1:]\n",
    "            # values[-1] = metric_value  \n",
    "              \n",
    "            #voting by majority\n",
    "            votes = 0\n",
    "            if color_value>color_thresh:\n",
    "                votes+=2\n",
    "            if bright_value>bright_thresh:\n",
    "                votes+=1\n",
    "            if mse_value>mse_thresh:\n",
    "                votes+=1\n",
    "            if abs_value>abs_thresh:\n",
    "                votes+=1\n",
    "            if canny_edge_value>canny_thresh:\n",
    "                votes+=1\n",
    "            if votes>=4 and idx>2:  \n",
    "                metric_values.append(1)   \n",
    "                scene_changes.append(idx)\n",
    "            else:\n",
    "                metric_values.append(0)\n",
    "        else:\n",
    "            metric_values.append(0)\n",
    "            mse_values.append(0)\n",
    "            mse_values.append(0)\n",
    "            abs_values.append(0)\n",
    "            canny_values.append(0)\n",
    "            bright_values.append(0)\n",
    "            color_values.append(0)\n",
    "        prev_frame = frame\n",
    "\n",
    "\n",
    "        ###  END CODE HERE  ###\n",
    "    \n",
    "    model = pickle.load(open(\"model.pkl\", 'rb')) \n",
    "    X_test = np.array(metric_values).reshape(-1, 1)  \n",
    "    predict_cuts = model.predict(X_test)\n",
    "    \n",
    "    return np.where(predict_cuts == 1)[0], vis, metric_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score \n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_subsample(x,y,subsample_size=1.0):\n",
    "\n",
    "    class_xs = []\n",
    "    min_elems = None\n",
    "\n",
    "    for yi in np.unique(y):\n",
    "        elems = x[(y == yi)]\n",
    "        class_xs.append((yi, elems))\n",
    "        if min_elems == None or elems.shape[0] < min_elems:\n",
    "            min_elems = elems.shape[0]\n",
    "\n",
    "    use_elems = min_elems\n",
    "    if subsample_size < 1:\n",
    "        use_elems = int(min_elems*subsample_size)\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    for ci,this_xs in class_xs:\n",
    "        if len(this_xs) > use_elems:\n",
    "            np.random.shuffle(this_xs)\n",
    "\n",
    "        x_ = this_xs[:use_elems]\n",
    "        y_ = np.empty(use_elems)\n",
    "        y_.fill(ci)\n",
    "\n",
    "        xs.append(x_)\n",
    "        ys.append(y_)\n",
    "\n",
    "    xs = np.concatenate(xs)\n",
    "    ys = np.concatenate(ys)\n",
    "\n",
    "    return xs,ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_videos = ['04','05']\n",
    "\n",
    "X_train, y_train = get_train_data(train_videos)\n",
    "# X,y = balanced_subsample(x,y)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 45)\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "prediction = model.predict(X_train)\n",
    "print(sklearn.metrics.classification_report(y_train,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_grid = {'C':[1,10,100,1000],'gamma':[1,0.1,0.001,0.0001], 'kernel':['linear','rbf']}\n",
    "grid = GridSearchCV(SVC(),param_grid,refit = True, verbose=2, scoring='f1')\n",
    "grid.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predic = grid.predict(X_train.reshape(-1,1))\n",
    "print(sklearn.metrics.classification_report(y_train,predic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'C': 1, 'gamma': 1, 'kernel': 'linear'}\n",
    "\n",
    "\n",
    "\n",
    "model = SVC(**p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_train.reshape(-1,1))\n",
    "print(sklearn.metrics.classification_report(y_train, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open(\"model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим ваше решение на всех видео.\n",
    "\n",
    "Не забывайте о том, что при итоговой оценке решений будет использоваться другой набор видео. Не переобучите модель!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dataset_path = 'train_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_num = 1\n",
    "run_scene_change_detector_ml_one_video(scene_change_detector_ml, 'train_dataset', video_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_scene_change_detector_all_video(scene_change_detector_ml, video_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Советы**\n",
    "\n",
    "* Используйте кросс-валидацию\n",
    "* Подумайте как лучше разделять видео на тренировочную и тестовые выборки\n",
    "* Подбирайте параметры модели (в библиотеке sklearn есть метод GridSearchCV для автоматического подбора параметров)\n",
    "* Пробуйте разные методы машинного обучения (из sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бонусное задание: детектор смен сцен типа наложение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично детектору из задания №1 за исключением того, что можно (и нужно) использовать машинное обучение:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED CELL: scene_change_detector_dissolve_ml\n",
    "\n",
    "def scene_change_detector_dissolve_ml(frames, threshold=None, with_vis=False):\n",
    "    scene_changes = []\n",
    "    vis = []\n",
    "    metric_values = []\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Ваши внешние переменные\n",
    "    ###  END CODE HERE  ###\n",
    "    \n",
    "    for idx, frame in tqdm(enumerate(frames), leave=False):\n",
    "        # frame - это кадр\n",
    "        # idx - это номер кадра\n",
    "        \n",
    "        ### START CODE HERE ###\n",
    "        # Основная часть вашего алгоритма\n",
    "        ###  END CODE HERE  ###\n",
    "\n",
    "    return scene_changes, vis, metric_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dataset_path = 'train_dataset'\n",
    "#Протестируем разработанный вами метод\n",
    "run_scene_change_detector_all_video_dissolve(scene_change_detector_dissolve, video_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваши ощущения ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Как и в первой части интересно узнать какие моменты показались простыми, а какие сложными. Много ли времени ушло на изучение sklearn и методов машинного обучения. Дало ли машинное обучение сразу прирост по сравнению с эврестической частью? Как вы контролировали переобучение?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
